<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>At-Least-Once Delivery · Akka Streams Kafka</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content='akka-stream-kafka-docs'/>
<link href="https://fonts.googleapis.com/css?family=Roboto:100normal,100italic,300normal,300italic,400normal,400italic,500normal,500italic,700normal,700italic,900normal,900italicc" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="css/page.css"/>

<!--
<link rel="shortcut icon" href="images/favicon.ico" />
-->
</head>

<body>
<div class="off-canvas-wrapper">
<div class="off-canvas-wrapper-inner" data-off-canvas-wrapper>

<div class="off-canvas position-left" id="off-canvas-menu" data-off-canvas>
<nav class="off-canvas-nav">
<div class="nav-home">
<a href="home.html" >
<span class="home-icon">⌂</span>Akka Streams Kafka
</a>
<div class="version-number">
0.15*
</div>
</div>
<div class="nav-toc">
<ul>
  <li><a href="producer.html">Producer</a></li>
  <li><a href="consumer.html">Consumer</a></li>
  <li><a href="atleastonce.html" class="active">At-Least-Once Delivery</a></li>
</ul>
</div>

</nav>
</div>

<div class="off-canvas-content" data-off-canvas-content>

<header class="site-header expanded row">
<div class="small-12 column">
<a href="#" class="off-canvas-toggle hide-for-medium" data-toggle="off-canvas-menu"><svg class="svg-icon svg-icon-menu" version="1.1" id="Menu" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 20 20" enable-background="new 0 0 20 20" xml:space="preserve"> <path class="svg-icon-menu-path" fill="#53CDEC" d="M16.4,9H3.6C3.048,9,3,9.447,3,10c0,0.553,0.048,1,0.6,1H16.4c0.552,0,0.6-0.447,0.6-1C17,9.447,16.952,9,16.4,9z M16.4,13
H3.6C3.048,13,3,13.447,3,14c0,0.553,0.048,1,0.6,1H16.4c0.552,0,0.6-0.447,0.6-1C17,13.447,16.952,13,16.4,13z M3.6,7H16.4
C16.952,7,17,6.553,17,6c0-0.553-0.048-1-0.6-1H3.6C3.048,5,3,5.447,3,6C3,6.553,3.048,7,3.6,7z"/></svg>
</a>
<div class="title"><a href="home.html" class="logo" style="margin-top: 15px;"><svg class="svg-icon svg-icon-logo" style="height: 45px; width: 184px;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1070 262"><title>akka-stream-kafka</title><g id="akka-stream-kafka" class="svg-icon-logo-text" fill="#fff"><path d="M349.6 105.5v-12.2h19.9v58.4c0 7.1 1.7 9.8 6.1 9.8 1.2 0 2.7-.2 4.1-.3v16.1c-2.2.8-5.5 1.3-9.8 1.3-4.8 0-8.6-.8-11.6-2.7-3.7-2.5-6-5.8-6.8-10.1-5.8 8.8-15.4 13.1-28.7 13.1-11.8 0-21.7-4.1-29.9-12.6-8-8.5-12-18.8-12-31.2s4-22.7 12-31c8.1-8.5 18.1-12.6 29.9-12.6 13.6 0 23.7 6 26.8 14zm-5.9 47.9c5-4.8 7.5-11 7.5-18.3s-2.5-13.4-7.5-18.3c-4.8-4.8-11-7.3-18.1-7.3-7.1 0-12.9 2.5-17.8 7.3-4.6 4.8-7 11-7 18.3s2.3 13.4 7 18.3c4.8 4.8 10.6 7.3 17.8 7.3 7.1 0 13.3-2.5 18.1-7.3zM388.5 177v-115.7h19.8v67.6l30.9-35.5h22.8l-32.7 37.4 36.2 46.3h-22.6l-26.4-33.7-8.3 9.3v24.3h-19.7zM470.8 177v-115.7h19.8v67.6l30.9-35.5h22.9l-32.7 37.4 36.2 46.3h-22.6l-26.4-33.7-8.3 9.3v24.3h-19.8zM607.9 105.5v-12.2h19.9v58.4c0 7.1 1.7 9.8 6.1 9.8 1.2 0 2.7-.2 4.1-.3v16.1c-2.2.8-5.5 1.3-9.8 1.3-4.8 0-8.6-.8-11.6-2.7-3.7-2.5-6-5.8-6.8-10.1-5.8 8.8-15.4 13.1-28.7 13.1-11.8 0-21.7-4.1-29.9-12.6-8-8.5-12-18.8-12-31.2s4-22.7 12-31c8.1-8.5 18.1-12.6 29.9-12.6 13.5 0 23.6 6 26.8 14zm-6 47.9c5-4.8 7.5-11 7.5-18.3s-2.5-13.4-7.5-18.3c-4.8-4.8-11-7.3-18.1-7.3-7.1 0-12.9 2.5-17.8 7.3-4.6 4.8-7 11-7 18.3s2.3 13.4 7 18.3c4.8 4.8 10.6 7.3 17.8 7.3 7.1 0 13.3-2.5 18.1-7.3z"/></g><path fill="#0B5567" d="M230.3 212.8c35.9 28.7 58.9-57 1.7-72.8-48-13.3-96.3 9.5-144.7 62.7 0 0 89.4-32.7 143 10.1z"/><path fill="#15A9CE" d="M88.1 202c34.4-35.7 91.6-75.5 144.9-60.8 12.4 3.5 21.2 10.7 26.9 19.3l-50.4-101.7c-7.2-11.5-25.6-9.1-36-.3l-133.2 111.6c-12.1 10.4-12.8 28.9-1.6 40.1 9.9 9.9 25.6 10.8 36.5 2l12.9-10.2z"/></g></svg>
</a></div>

<!--
<a href="https://www.example.com" class="logo show-for-medium">logo</a>
-->
</div>
</header>

<div class="expanded row">

<div class="medium-3 large-2 show-for-medium column">
<nav class="site-nav">
<div class="nav-home">
<a href="home.html" >
<span class="home-icon">⌂</span>Akka Streams Kafka
</a>
<div class="version-number">
0.15*
</div>
</div>
<div class="nav-toc">
<ul>
  <li><a href="producer.html">Producer</a></li>
  <li><a href="consumer.html">Consumer</a></li>
  <li><a href="atleastonce.html" class="active">At-Least-Once Delivery</a></li>
</ul>
</div>

</nav>
</div>

<div class="small-12 medium-9 large-10 column">
<section class="site-content">

<div class="page-header row">
<div class="medium-12 show-for-medium column">
<div class="nav-breadcrumbs">
<ul>
  <li><a href="home.html">Akka Streams Kafka</a></li>
  <li>At-Least-Once Delivery</li>
</ul>
</div>
</div>
</div>

<div class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#at-least-once-delivery" name="at-least-once-delivery" class="anchor"><span class="anchor-link"></span></a>At-Least-Once Delivery</h1>
<p>At-least-once delivery semantics, the requirement to process every message, is a basic requirement of most applications. </p>
<p>When using committable sources (<a href="consumer.html#offset-storage-in-kafka">Offset Storage in Kafka</a>), care is needed to ensure at-least-once delivery semantics are not lost inadvertently by committing an offset too early.</p>
<p>Below are some scenarios where this risk is present. These risks can easily be overlooked. Problems can also go undetected during tests since they depend on abruptly interrupting the flow in a particular state, and that state could be unlikely to occur. </p>
<h2><a href="#multiple-effects-per-commit" name="multiple-effects-per-commit" class="anchor"><span class="anchor-link"></span></a>Multiple Effects per Commit</h2>
<h3><a href="#multiple-messages" name="multiple-messages" class="anchor"><span class="anchor-link"></span></a>Multiple Messages</h3>
<p>When connecting a committable source to a producer flow, some applications may require each consumed message to produce more than one message. In that case, in order to preserve at-least-once semantics, the message offset should only be committed after all associated messages have been produced.</p>
<p>To achieve this, it will no longer be sufficient to pass a <code>CommittableOffset</code> in the <code>passThrough</code> field of <code>ProducerMessage.Message</code>. Instead the type used for <code>PassTrough</code> should be one that can also encode the absence of an offset. Two valid choices would be <code>Option[CommittableOffset]</code> or a <code>CommittableOffsetBatch</code>. Currently two instances of <code>CommittableOffsetBatch</code> cannot be mergerd together, which will be a problem if we want to create batches, so using an <code>Option[CommittableOffset]</code> is preferable. </p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">Consumer.committableSource(consumerSettings, Subscriptions.topics(&quot;topic1&quot;))
  .mapConcat(msg =&gt;
    List(
      ProducerMessage.Message(
        new ProducerRecord[Array[Byte], String](&quot;topic2&quot;, msg.record.value),
        None
      ),
      ProducerMessage.Message(
        new ProducerRecord[Array[Byte], String](&quot;topic2&quot;, msg.record.value),
        Some(msg.committableOffset)
      )
    ))
  .via(Producer.flow(producerSettings))
  .map(_.message.passThrough)
  .collect{case Some(offset) =&gt; offset}
  .batch(max = 20, CommittableOffsetBatch.empty.updated(_))(_.updated(_))
  .mapAsync(3)(_.commitScaladsl())
  .runWith(Sink.ignore)</code></pre></dd>
</dl>
<p>Here a <code>collect</code> is used to filter away all the <code>None</code> values, and unwrap the <code>CommitableOffset</code> instances from the <code>Option</code> before sending them to the batch stage.</p>
<h3><a href="#batches" name="batches" class="anchor"><span class="anchor-link"></span></a>Batches</h3>
<p>If committable messages are processed in batches (using <code>batch</code> or <code>grouped</code>), it is also important to commit the resulting <code>CommitableOffsetBatch</code> only after all messages in the batch are fully processed.</p>
<p>Should the batch need to be split up again, using mapConcat, care should be taken to associate the <code>CommitableOffsetBatch</code> only with the last message. This scenario could occur if we created batches to more efficiently update a database and then needed to split up the batches to send individual messages to a Kafka producer flow.</p>
<h3><a href="#multiple-destinations" name="multiple-destinations" class="anchor"><span class="anchor-link"></span></a>Multiple Destinations</h3>
<p>In the Conditional Message Processing section below we discuss how to handle producing to multiple Kafka topics, but here we consider writing to other types of persistent storage, or performing other side-effects, perhaps in addition to producing to Kafka topics.</p>
<p>To commit an offset or an offset batch only after the multiple effects have been performed, we will usually want to asssemble our side-effecting flows in series, one after the other. This still allows the side effects to be performed concurrently on distinct messages, using <code>mapAsync</code> for example.</p>
<p>Alternatively, we could split-off the flow using <code>alsoTo</code> to perform the effects in distinct parallel flows. We would then use <code>zip</code> to bring the two flows back together and re-associate the matching committable offsets. This step is important to ensure that we only commit an offset once the effects from both flows are complete. This constrains the two flows to output the exact same sequence of committable offsets. So this approach may not be significantly more flexible then a serial arrangement.</p>
<h2><a href="#non-sequential-processing" name="non-sequential-processing" class="anchor"><span class="anchor-link"></span></a>Non-Sequential Processing</h2>
<p>Messages from committable sources should be processed in order, otherwise a larger offset for a partition could be committed before the work associated to a smaller offset has been completed.</p>
<p>Reordering would be acceptable if the original order was reconstituted before committing the offsets, but that is a fairly complex and possibly brittle process that we will not consider here.</p>
<p>Using <code>mapAsync</code> is safe since it preserves the order of messages. That is in constrast to <code>mapAsyncUnordered</code> which would not be safe to use here. As indicated in the <a href="http://doc.akka.io/docs/akka/2.4.17/scala/stream/stream-flows-and-basics.html#Stream_ordering">Akka Streams documentation</a> almost all stages will preserve input ordering.</p>
<h3><a href="#using-groupby" name="using-groupby" class="anchor"><span class="anchor-link"></span></a>Using groupBy</h3>
<p>Using <code>groupBy</code> followed at some point by a <code>mergeSubstreams</code> can reorder messages, so in general it is not safe with respect to the at-least-once guarantee.</p>
<p>However it can only lead to reordering between messages sent to different substreams, so it is possible to use <code>groupBy</code> and preserve at-least-once semantics as long as all messages from the same partition are sent to the same substream.</p>
<p>If a particular substream expects to see all messages regarding some entity, it then requires that writers to the source topic become responsible for placing messages about various entities in the appropriate partitions. If your application already has a requirement to preserve the order of messages about a particular entity within a Kafka topic, you will already need to ensure those messages go to the same partition since Kafka only preserves order information within a partition.</p>
<h2><a href="#conditional-message-processing" name="conditional-message-processing" class="anchor"><span class="anchor-link"></span></a>Conditional Message Processing</h2>
<p>Most flows will require some messages to be handled differently from others. Unfortunately this is difficult to do while preserving the at-least-once guarantee because the order of messages must be maintained.</p>
<p>We cannot safely send off the messages to be handled differently to a distinct flow: this other flow cannot commit on its own, and even if merge it back, downstream, with the main flow, ordering will not be preserved. The reason the separate flow cannot commit on its own is that it will only be seeing a subset of the committable messages. If it commits an offset, it cannot know that all prior offsets have been processed in the main flow.</p>
<p>This is a significant challenge. Below we suggest a few strategies to deal with some special cases of this general problem.</p>
<h3><a href="#publishing-to-message-dependent-topics" name="publishing-to-message-dependent-topics" class="anchor"><span class="anchor-link"></span></a>Publishing to Message-Dependent Topics</h3>
<p>Since <code>ProducerRecord</code> contains the destination topic, it is possible to use a single producer flow to write to any number of topics. This preserves the ordering of messages coming from the committable source. Since the destination topics likely admit different types of messages, it will be necessary to serialize the messages to the appropriate input type for the common producer flow, which could be a byte array or a string.</p>
<p>Each committable message may safely lead to the production of more than one message, as long as the <code>CommittableOffset</code> is associated to the last message, as described earlier.</p>
<p>However if a committable message leads to the production of no messages, then we have a problem: the producer flow is not currently able to pass through a committable offset without producing a message.</p>
<h3><a href="#excluding-messages" name="excluding-messages" class="anchor"><span class="anchor-link"></span></a>Excluding Messages</h3>
<p>Failure to deserialize a message is a particular case of conditional message processing. It is also likely that we would have no message to produce to Kafka when we encounter messages that fail to deserialize. As described above, the producer flow will not less us pass through the corresponding committable offset without producing a message. </p>
<p>Why can&rsquo;t we commit the offsets of bad messages as soon as we encounter them, instead of try passing them on, downstream? Because the previous offsets, for messages that have deserialized successfully, may not have been committed yet. That&rsquo;s possible if the downstream flow includes a buffer, an aynchronous boundary or performs batching. It is then likely that some previous messages would concurrently be making their way downstream to a final committing stage.</p>
<p>Note that here we assume that we take the full control over the handling of messages that fail to deserialize. To do this, we should not ask for the deserialization to be performed by the commitable source. We can instead create a <code>ConsumerSettings</code> parametrized by byte arrays. A subsequent <code>collect</code> can deserialize and skip bad messages. Alternatively a <code>map</code> stage can be used should we wish to propagate downstream some information about the bad messages, such as their committable offsets.</p>
<p>If bad messages are rare, it might be acceptable to never commit their offsets directly and instead rely on the commit of the next deserializable message to eventually advance the partition beyond the bad messages. This preserves at-least-once semantics, but can lead to more frequent duplicated handling of bad messages on restarts. However that handling might may not have very important effects: it might simply be logging the message.</p>
</div>
<div class="large-3 show-for-large column" data-sticky-container>
<nav class="sidebar sticky" data-sticky data-anchor="docs" data-sticky-on="large">
<div class="page-nav">
<div class="nav-title">On this page:</div>
<div class="nav-toc">
<ul>
  <li><a href="atleastonce.html#at-least-once-delivery">At-Least-Once Delivery</a>
  <ul>
    <li><a href="atleastonce.html#multiple-effects-per-commit">Multiple Effects per Commit</a>
    <ul>
      <li><a href="atleastonce.html#multiple-messages">Multiple Messages</a></li>
      <li><a href="atleastonce.html#batches">Batches</a></li>
      <li><a href="atleastonce.html#multiple-destinations">Multiple Destinations</a></li>
    </ul></li>
    <li><a href="atleastonce.html#non-sequential-processing">Non-Sequential Processing</a>
    <ul>
      <li><a href="atleastonce.html#using-groupby">Using groupBy</a></li>
    </ul></li>
    <li><a href="atleastonce.html#conditional-message-processing">Conditional Message Processing</a>
    <ul>
      <li><a href="atleastonce.html#publishing-to-message-dependent-topics">Publishing to Message-Dependent Topics</a></li>
      <li><a href="atleastonce.html#excluding-messages">Excluding Messages</a></li>
    </ul></li>
  </ul></li>
</ul>
</div>
</div>
</nav>
</div>
</div>

</section>
</div>

</div>

<footer class="site-footer">

<section class="site-footer-nav">
<div class="expanded row">
<div class="small-12 large-offset-2 large-10 column">
<div class="row site-footer-content">

<div class="small-12 medium-4 large-3 text-center column">
<div class="nav-links">
<ul>
<!-- <li><a href="https://www.example.com/products/">Products</a> -->
</ul>
</div>
</div>

</div>
</div>
</div>
</section>

<section class="site-footer-base">
<div class="expanded row">
<div class="small-12 large-offset-2 large-10 column">
<div class="row site-footer-content">

<div class="small-12 text-center large-9 column">

<!--
<div class="copyright">
<span class="text">&copy; 2017</span>
<a href="https://www.example.com" class="logo">logo</a>
</div>
-->
</div>

</div>
</div>
</div>
</section>
</footer>

</div>
</div>
</div>
</body>

<script type="text/javascript" src="lib/foundation/dist/foundation.min.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/magellan.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>

</html>
